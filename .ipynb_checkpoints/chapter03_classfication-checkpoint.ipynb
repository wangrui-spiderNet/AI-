{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在第一章中我们提到最常见的监督学习任务是回归(预测值)和分类(预测类)。在第2章中，我们探索\n",
    "# 了一个回归任务，预测房屋价值，使用各种算法，如线性回归，决策树，和随机森林(这将在后面的\n",
    "# 章节中进一步详细解释)。现在我们将注意力转向分类系统。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST\n",
    "# 在这一章中，我们将使用mnist的数据集，它是一组由美国人口普查局的高中生和雇员手写的7万张\n",
    "# 数字小图像。每个图像都用它所代表的数字标记。这个集合被研究得如此之多，以至于它经常被称\n",
    "# 为机器学习的“hello world”:每当人们提出一种新的分类算法时，他们都很好奇它在mnist上会有\n",
    "# 什么表现。每当有人学习机器学习时，他们迟早会遇到MNIST。\n",
    "\n",
    "# scikit - learn提供了许多帮助函数来下载流行的数据集。mnist就是其中之一。以下代码获取\n",
    "# MNIST数据集:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:77: DeprecationWarning: Function fetch_mldata is deprecated; fetch_mldata was deprecated in version 0.20 and will be removed in version 0.22\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:77: DeprecationWarning: Function mldata_filename is deprecated; mldata_filename was deprecated in version 0.20 and will be removed in version 0.22\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'DESCR': 'mldata.org dataset: mnist-original',\n",
       " 'COL_NAMES': ['label', 'data'],\n",
       " 'target': array([0., 0., 0., ..., 9., 9., 9.]),\n",
       " 'data': array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]], dtype=uint8)}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_mldata\n",
    "mnist = fetch_mldata(\"MNIST original\")\n",
    "mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scikit - learn加载的数据集通常具有类似的字典结构，包括:\n",
    "# * 描述数据集的descr键\n",
    "# * 一种数据键，包含每个实例一行和每个特性一列的数组\n",
    "# * 包含带有标签的数组的目标键\n",
    "x,y=mnist[\"data\"],mnist[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, 784)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 有70,000张图片，每张图片有784个特征。这是因为每个图像28×28个像素,每个功能仅仅代表一个\n",
    "# 像素的强度,从0(白色)255(黑色)。让我们从数据集中看一个数字。所有你需要做的是抓住一个实\n",
    "# 例的特征向量,重塑一个28×28个数组,并将其显示使用matplotlib imshow()函数:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "some_digit = x[36000]\n",
    "some_digit_image=some_digit.reshape(28,28)\n",
    "\n",
    "plt.imshow(some_digit_image,cmap = matplotlib.cm.binary,interpolation=\"nearest\")\n",
    "\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[36000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train (60000, 784)\n"
     ]
    }
   ],
   "source": [
    "# 但是等等!在仔细检查数据之前，您应该始终创建一个测试集并将其放在一边。mnist数据集实际上\n",
    "# 已经分为训练集(最初的60000张图片)和测试集(最后的10000张图片):\n",
    "\n",
    "x_train,x_test,y_train,y_test=x[:60000],x[60000:],y[:60000],y[60000:]\n",
    "print(\"x_train\",x_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 我们来洗牌训练集;这将确保所有交叉验证折叠都是相似的(您不希望一个折叠丢失一些数字)。此外，\n",
    "# 一些学习算法对训练实例的顺序很敏感，如果连续得到许多相似的实例，它们的性能会很差。对数\n",
    "# 据集进行洗牌确保不会发生这种情况:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "shuffle_index = np.random.permutation(60000)\n",
    "x_train,y_train=x_train[shuffle_index],y_train[shuffle_index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练一个Binary 分类器\n",
    "# 现在让我们简化一下这个问题，只尝试识别一个数字——例如数字5。这个“5检测器”将是二进制\n",
    "# 分类器的一个示例，能够区分5和非5这两个类。让我们为这个分类任务创建目标向量:\n",
    "\n",
    "y_train_5 = (y_train == 5)\n",
    "y_test_5 = (y_test == 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 好的，现在让我们选择一个分类器并训练它。一个好的开始是使用scikit - learn的sgdclassifier，\n",
    "# 使用随机梯度下降(SGD)分类器。这种分类器的优点是能够有效地处理非常大的数据集。这在一定程\n",
    "# 度上是因为sgd独立处理培训实例，一次一个(这也使得sgd非常适合在线学习)，稍后我们将看到这\n",
    "# 一点。让我们创建一个sgdclassifier并在整个训练集上对它进行训练:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
       "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
       "       l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=None,\n",
       "       n_iter=None, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
       "       power_t=0.5, random_state=42, shuffle=True, tol=None,\n",
       "       validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "sgd_clf = SGDClassifier(random_state = 42)\n",
    "sgd_clf.fit(x_train,y_train_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 注意：\n",
    "# sgdclassifier依赖于训练过程中的随机性(因此得名“随机”)。如果您想要可重复的结果，\n",
    "# 您应该设置random_state参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd_clf.predict([some_digit])\n",
    "# 分类器猜测该图像表示5 (True)。看起来在这个特殊的情况下它猜对了!现在，让我们评估这个模型\n",
    "# 的性能。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 性能检测\n",
    "# 评价一个分类器通常比评价一个回归器要复杂得多，所以我们将在本章的大部分时间里讨论这个主\n",
    "# 题。有许多可用的性能度量方法，所以请再喝一杯咖啡，并准备学习许多新概念和首字母缩写!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 交叉验证测量精度\n",
    "# 评估模型的一个好方法是使用交叉验证，就像您在第2章中所做的那样。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.83725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.90535\n"
     ]
    }
   ],
   "source": [
    "# 实现交叉验证\n",
    "# 有时候，您需要对交叉验证过程进行更多的控制，而不是使用cross_val_score()和类似的函数。\n",
    "# 在这些情况下，您可以自己实现交叉验证;其实很简单。下面的代码与前面的cross_val_score()\n",
    "# 代码大致相同，并打印相同的结果:\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.base import clone\n",
    "\n",
    "\n",
    "skfolds= StratifiedKFold(n_splits=3,random_state=42)\n",
    "\n",
    "# def cross_validate_way(skfolds):\n",
    "for train_index,test_index in skfolds.split(x_train,y_train_5):\n",
    "    clone_slf= clone(sgd_clf)\n",
    "    \n",
    "    x_train_folds=x_train[train_index]\n",
    "    y_train_folds=(y_train_5[train_index])\n",
    "    x_test_fold=x_train[test_index]\n",
    "    y_test_fold=(y_train_5[test_index])\n",
    "    \n",
    "    clone_slf.fit(x_train_folds,y_train_folds)\n",
    "    y_pred=clone_slf.predict(x_test_fold)\n",
    "    n_correct=sum(y_pred==y_test_fold)\n",
    "    print(n_correct/len(y_pred))\n",
    "\n",
    "# cross_validate_way(skfolds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# StratifiedKFold类执行分层采样(如第2章所述)，生成包含每个类别的代表性比例的fold。在每次\n",
    "# 迭代中，代码创建分类器的克隆，在训练折叠上训练该克隆，并对测试折叠进行预测。然后计算正\n",
    "# 确预测的次数，输出正确预测的比例。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.869  , 0.83725, 0.90535])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 让我们使用cross_val_score()函数使用k -fold交叉验证来评估sgdclassifier模型，该验证有三个\n",
    "# 褶。记住，k -fold cross-validation意味着将训练集分割为k -fold(在本例中是3个)，然后进行\n",
    "# 预测，并使用在其余折叠上训练的模型对每个折叠进行评估(参见第2章):\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cross_val_score(sgd_clf,x_train,y_train_5,cv=3,scoring=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 哇!所有交叉验证折叠的准确率超过95%(正确预测的比率)?这看起来很神奇，不是吗?好吧，在你太\n",
    "# 兴奋之前，让我们看看一个非常愚蠢的分类器，它只对“not-5”类中的每一张图片进行分类:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.     , 0.72895, 1.     ])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "import numpy as np\n",
    "\n",
    "class Never5Classifier(BaseEstimator):\n",
    "    def fit(self,x,y=None):\n",
    "        pass\n",
    "    def predict(self,x):\n",
    "        return np.zeros((len(x),1),dtype=bool)\n",
    "\n",
    "never_5_clf = Never5Classifier()\n",
    "cross_val_score(never_5_clf,x_train,y_train_5,cv=3,scoring=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 没错，它的准确率超过90% !这仅仅是因为只有10%的图像是5s，所以如果您总是猜测图像不是5，\n",
    "# 那么90%的情况下您是正确的。胜过占卜者。这说明了为什么精度通常不是分类器的首选性能度量，\n",
    "# 尤其是在处理倾斜数据集(例如(有些课程比其他课程更频繁)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion\tMatrix  混淆矩阵\n",
    "# 评价分类器性能的一种更好的方法是查看混淆矩阵。一般的思路是计算a类实例被分类为b类的次数。\n",
    "# 例如，要知道分类器混淆5s和3s的图像的次数，你需要查看混淆矩阵的第5行和第3列。\n",
    "\n",
    "# 要计算混淆矩阵，首先需要有一组预测，以便与实际目标进行比较。您可以对测试集进行预测，但\n",
    "# 是现在让我们保持原样(记住，一旦您准备好了要启动的分类器，您希望只在项目的最后使用测试集)。\n",
    "# 相反，您可以使用cross_val_predict()函数:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "y_train_pred = cross_val_predict(sgd_clf,x_train,y_train_5,cv=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False,  True, False, ..., False, False, False])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 与cross_val_score()函数类似，cross_val_predict()执行k -fold交叉验证，但是它不返回评估得\n",
    "# 分，而是返回对每个测试折叠所做的预测。这意味着您可以为训练集中的每个实例获得一个清晰的\n",
    "# 预测(“清晰”意味着预测是由一个在训练期间从未看到数据的模型做出的)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 现在，您已经准备好使用confusion_matrix()函数获得混乱矩阵。只需将目标类(y_train_5)和预测\n",
    "# 类(y_train_pred)传递给它:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[47700,  6879],\n",
       "       [  889,  4532]], dtype=int64)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(y_train_5,y_train_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 混淆矩阵中的每一行表示实际的类，而每一列表示预测的类。这个矩阵的第一行考虑的是非5图像\n",
    "# (negative类):其中47,770张被正确分类为非5s(称为true negative)，其余6,879张被错误分类为5s\n",
    "# (false nagtive)。第二行考虑5s(positive 类)图像:889张错误归类为非5s(false nagetive)，\n",
    "# 4532张错误归类为5s(true positive)。一个完美的分类器只有true positive和true negative，所以它的混淆矩阵\n",
    "# 只有在主对角线上(从左上角到右下角)才有非零值:\n",
    "# array([\n",
    "#       [54579,0],\n",
    "#       [0,5421]\n",
    "#       ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 混淆矩阵提供了许多信息，但有时您可能更喜欢更简洁的度量。一个有趣的现象是正面预测的准确\n",
    "# 性;这称为分类器的精度(公式3-1)。\n",
    "# 精度(precision) = Tp/(TP+FP)\n",
    "\n",
    "# TP是true positive的数量，FP是false negative的数量。\n",
    "\n",
    "# 要获得完美的精度，一个简单的方法是进行一次正面的预测，并确保它是正确的(精度= 1/1 = 100%)。\n",
    "# 这将不是很有用，因为分类器将忽略除一个正面实例之外的所有实例。因此，精确度通常与另一个\n",
    "# 称为召回的度量标准一起使用，也称为灵敏度或真实阳性率(TPR):这是分类器正确检测到的阳性实\n",
    "# 例的比率(公式3-2)。\n",
    "\n",
    "# recall = TP/(TP+FN)\n",
    "# FN 是false negative的数量\n",
    "# 如果你对confusion matrix 感到困惑，3-2表格也许会帮到你。\n",
    "# \n",
    "# TP true positive: 真对 例如 5         是5，而且识别正确\n",
    "# NP nagative positive:假对  例如 3,6   不是5，但是错以为是5\n",
    "# TN true negative: 真错 例如 1,2,3,8   不是5，而且识别出来不是5\n",
    "# FN false negative: 假错 例如 5        是5，但是识别错误，以为不是5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
